{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195eb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jihun\\AppData\\Local\\Temp\\ipykernel_12244\\3401581085.py:20: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Masking, GRU, Flatten, Conv1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import MaxPooling1D, BatchNormalization, Dropout, ZeroPadding1D\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "102810a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_Beat_level로 수정해야함\n",
    "\n",
    "def load_BEAT_level(signal, r_peaks):\n",
    "    signal_list = []\n",
    "    for number in range(1,len(r_peaks['ECG_R_Peaks'])-1):\n",
    "        if len(signal[r_peaks['ECG_R_Peaks'][number]-231 : r_peaks['ECG_R_Peaks'][number]+469]) < 700:\n",
    "            continue\n",
    "        signal_list.append(signal[r_peaks['ECG_R_Peaks'][number]-231 : r_peaks['ECG_R_Peaks'][number]+469])\n",
    "    return np.array(signal_list)\n",
    "\n",
    "def shuffle_data(data, labels):\n",
    "    # data와 label을 입력받아 무작위로 섞고 (인덱스 위치는 동일하게) Return\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data[indices], labels[indices]\n",
    "\n",
    "# Beat level에 맞게 수정 \n",
    "def load_data(subjects):\n",
    "    # Concatenate 함수를 사용하기 전에 리스트 대신 NumPy 배열 사용\n",
    "    normal_data, stress_data, amuse_data = [], [], []\n",
    "    normal_label, stress_label, amuse_label = [], [], []\n",
    "\n",
    "    for i in subjects:\n",
    "        df = pd.read_pickle(Data + i + '/' + i + '.pkl')\n",
    "        ecg_v = df['signal']['chest']['ECG']\n",
    "        label = df['label']\n",
    "\n",
    "        amuse_ecg = ecg_v[np.where(label == 3)[0]].flatten()\n",
    "        normal_ecg = ecg_v[np.where(label == 1)[0]].flatten()\n",
    "        stress_ecg = ecg_v[np.where(label == 2)[0]].flatten()\n",
    "        \n",
    "        _, amuse_rpeaks = nk.ecg_peaks(amuse_ecg, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "        _, normal_rpeaks = nk.ecg_peaks(normal_ecg, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "        _, stress_rpeaks = nk.ecg_peaks(stress_ecg, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "        \n",
    "\n",
    "        amuse_data.append(load_BEAT_level(amuse_ecg, amuse_rpeaks))\n",
    "        normal_data.append(load_BEAT_level(normal_ecg, normal_rpeaks))\n",
    "        stress_data.append(load_BEAT_level(stress_ecg, stress_rpeaks))\n",
    "    \n",
    "    amuse = np.vstack(amuse_data)\n",
    "    normal = np.vstack(normal_data)\n",
    "    stress = np.vstack(stress_data)\n",
    "    \n",
    "    amuse_label = np.zeros(amuse.shape[0], np.int32)\n",
    "    normal_label = np.ones(normal.shape[0], np.int32)\n",
    "    stress_label = 2*np.ones(stress.shape[0], np.int32)\n",
    "    \n",
    "    Train = np.concatenate([amuse, normal, stress])\n",
    "    Train_label = np.concatenate([amuse_label, normal_label, stress_label])\n",
    "    \n",
    "    train, train_y = shuffle_data(Train, Train_label)\n",
    "    \n",
    "    return train, train_y\n",
    "\n",
    "\n",
    "# Plot \n",
    "def Plot_lr_curve(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    #val_acc = history.history['val_accuracy'] \n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    #plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    #plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "def Plot_confusion_matrix(true_d, pred):\n",
    "    \n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "    for i in range(len(pred)):\n",
    "        pred_label.append(np.argmax(pred[i]))\n",
    "    \n",
    "    for i in range(len(true_d)):\n",
    "        true_label.append(np.argmax(true_d[i]))\n",
    "        \n",
    "        \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_label, pred_label)\n",
    "    print('accuracy : ', np.round(accuracy,3))\n",
    "    \n",
    "    # Precision\n",
    "    precision = precision_score(true_label, pred_label, average='macro')\n",
    "    print('precision : ', np.round(precision,3))\n",
    "    \n",
    "    # Recall\n",
    "    recall = recall_score(true_label, pred_label,average='macro')\n",
    "    print('recall : ', np.round(recall,3))\n",
    "    \n",
    "    # Specificity\n",
    "    specificity = recall_score(true_label, pred_label,average='macro')\n",
    "    print('specificity : ',np.round(specificity,3))\n",
    "    \n",
    "    # F1 Score\n",
    "    F1_score = f1_score(true_label, pred_label,average='macro')\n",
    "    print('F1_score : ', np.round(F1_score,3))\n",
    "\n",
    "    report = classification_report(true_label, pred_label, target_names=['Amuse', 'Normal','Stress'])\n",
    "    print(report)\n",
    "    confusion = confusion_matrix(true_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion, display_labels=['Amuse', 'Normal', 'Stress'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b6365",
   "metadata": {},
   "source": [
    "# 1DCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f258a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_78 (Conv1D)          (None, 691, 16)           176       \n",
      "                                                                 \n",
      " conv1d_79 (Conv1D)          (None, 682, 16)           2576      \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 341, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_80 (Conv1D)          (None, 332, 32)           5152      \n",
      "                                                                 \n",
      " conv1d_81 (Conv1D)          (None, 323, 32)           10272     \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 161, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 161, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 161, 32)           0         \n",
      "                                                                 \n",
      " conv1d_82 (Conv1D)          (None, 152, 64)           20544     \n",
      "                                                                 \n",
      " conv1d_83 (Conv1D)          (None, 143, 64)           41024     \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 71, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 62, 128)           82048     \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 53, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, 26, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 26, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 26, 128)           0         \n",
      "                                                                 \n",
      " conv1d_86 (Conv1D)          (None, 24, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_87 (Conv1D)          (None, 22, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_38 (MaxPoolin  (None, 11, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_88 (Conv1D)          (None, 9, 512)            393728    \n",
      "                                                                 \n",
      " conv1d_89 (Conv1D)          (None, 7, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 7, 512)           2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 7, 512)            0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 3584)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 512)               1835520   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,168,451\n",
      "Trainable params: 4,167,107\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_1Dmodel = tf.keras.Sequential([\n",
    "    Conv1D(16, 10, activation='relu', input_shape=(700, 1)),\n",
    "    Conv1D(16, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    \n",
    "    Conv1D(32, 10,activation='relu'),\n",
    "    Conv1D(32, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    \n",
    "    Conv1D(64, 10,activation='relu'),\n",
    "    Conv1D(64, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(128, 10,activation='relu'),\n",
    "    Conv1D(128, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(256, 3,activation='relu'),\n",
    "    Conv1D(256, 3,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(512, 3,activation='relu'),\n",
    "    Conv1D(512, 3,activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='LeakyReLU'),\n",
    "    Dense(1024, activation='LeakyReLU'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_1Dmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1e49f",
   "metadata": {},
   "source": [
    "# K-Fold (1D-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9199e2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 검증\n",
      "Train: [ 1  2  3  4  5  6  7  8 10 12 13 14] Test [ 0  9 11]\n",
      "Epoch 1/50\n",
      " 524/1089 [=============>................] - ETA: 8s - loss: 0.8020 - accuracy: 0.6819"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12244\\3611637692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mmodel_clone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCNN_1Dmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mmodel_clone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_clone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_clone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mPlot_lr_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\ecg1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial settings\n",
    "Data = \"D:/Database/WESAD/\"\n",
    "sampling_rate = 700\n",
    "n_split = 5 # num of Fold\n",
    "random_state = 42\n",
    "subjects = np.array(['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17'])\n",
    "accuracies = [] # Fold accuracy list\n",
    "fold_i = 0\n",
    "\n",
    "# K-fold Code start\n",
    "kf = KFold(n_splits=n_split, shuffle=True, random_state=random_state)\n",
    "\n",
    "for train_index, test_index in kf.split(subjects):\n",
    "    \n",
    "    fold_i += 1\n",
    "    print(fold_i, '번째 검증')\n",
    "    \n",
    "    train_subjects, test_subjects = subjects[train_index], subjects[test_index]\n",
    "    \n",
    "    # Train Data load\n",
    "    train_data, train_labels = load_data(train_subjects)\n",
    "    # Test Data load\n",
    "    test_data, test_labels = load_data(test_subjects)\n",
    "    \n",
    "    # One-hot Encoding\n",
    "    train_y = to_categorical(train_labels)\n",
    "    test_y = to_categorical(test_labels)\n",
    "    \n",
    "    print('Train:', train_index, 'Test', test_index)\n",
    "    \n",
    "    # Model Training \n",
    "    model_clone = clone_model(CNN_1Dmodel)\n",
    "    model_clone.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model_clone.fit(train_data, train_y, epochs=50, batch_size=32) \n",
    "    scores = model_clone.evaluate(test_data, test_y)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_clone.predict(test_data)\n",
    "    Plot_confusion_matrix(test_y, pred)\n",
    "    \n",
    "    \n",
    "    accuracies.append(scores[1])\n",
    "    \n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print('평균 정확도 : ', average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c91054",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "12bc88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 700, 128)          66560     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 700, 128)          0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 700, 128)          131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 700, 128)          0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,252,355\n",
      "Trainable params: 1,252,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = tf.keras.Sequential([\n",
    "    \n",
    "    LSTM(128, return_sequences=True, input_shape=(700,1)),\n",
    "    Dropout(0.5),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(256),\n",
    "    \n",
    "    Dense(512, activation='LeakyReLU'),\n",
    "    Dense(1024, activation='LeakyReLU'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba173dfb",
   "metadata": {},
   "source": [
    "# LSTM 5-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928801d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial settings\n",
    "Data = \"D:/Database/WESAD/\"\n",
    "sampling_rate = 700\n",
    "n_split = 5 # num of Fold\n",
    "random_state = 42\n",
    "subjects = np.array(['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17'])\n",
    "accuracies = [] # Fold accuracy list\n",
    "fold_i = 0\n",
    "\n",
    "# K-fold Code start\n",
    "kf = KFold(n_splits=n_split, shuffle=True, random_state=random_state)\n",
    "\n",
    "for train_index, test_index in kf.split(subjects):\n",
    "    \n",
    "    fold_i += 1\n",
    "    print(fold_i, '번째 검증')\n",
    "    \n",
    "    train_subjects, test_subjects = subjects[train_index], subjects[test_index]\n",
    "    \n",
    "    # Train Data load\n",
    "    train_data, train_labels = load_data(train_subjects)\n",
    "    # Test Data load\n",
    "    test_data, test_labels = load_data(test_subjects)\n",
    "    \n",
    "    # One-hot Encoding\n",
    "    train_y = to_categorical(train_labels)\n",
    "    test_y = to_categorical(test_labels)\n",
    "    \n",
    "    print('Train:', train_index, 'Test', test_index)\n",
    "    \n",
    "    # Model Training \n",
    "    model_clone = clone_model(LSTM_model)\n",
    "    model_clone.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model_clone.fit(train_data, train_y, epochs=50, batch_size=32) \n",
    "    scores = model_clone.evaluate(test_data, test_y)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_clone.predict(test_data)\n",
    "    Plot_confusion_matrix(test_y, pred)\n",
    "    \n",
    "    \n",
    "    accuracies.append(scores[1])\n",
    "    \n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print('평균 정확도 : ', average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba07190",
   "metadata": {},
   "source": [
    "# CNN-LSTM1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "19bc0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_48 (Conv1D)          (None, 691, 16)           176       \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, 682, 16)           2576      \n",
      "                                                                 \n",
      " max_pooling1d_20 (MaxPoolin  (None, 341, 16)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, 332, 32)           5152      \n",
      "                                                                 \n",
      " conv1d_51 (Conv1D)          (None, 323, 32)           10272     \n",
      "                                                                 \n",
      " max_pooling1d_21 (MaxPoolin  (None, 161, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 161, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 161, 32)           0         \n",
      "                                                                 \n",
      " conv1d_52 (Conv1D)          (None, 152, 64)           20544     \n",
      "                                                                 \n",
      " conv1d_53 (Conv1D)          (None, 143, 64)           41024     \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPoolin  (None, 71, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_54 (Conv1D)          (None, 62, 128)           82048     \n",
      "                                                                 \n",
      " conv1d_55 (Conv1D)          (None, 53, 128)           163968    \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPoolin  (None, 26, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 26, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 26, 128)           0         \n",
      "                                                                 \n",
      " conv1d_56 (Conv1D)          (None, 24, 256)           98560     \n",
      "                                                                 \n",
      " conv1d_57 (Conv1D)          (None, 22, 256)           196864    \n",
      "                                                                 \n",
      " max_pooling1d_24 (MaxPoolin  (None, 11, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_58 (Conv1D)          (None, 9, 512)            393728    \n",
      "                                                                 \n",
      " conv1d_59 (Conv1D)          (None, 7, 512)            786944    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 7, 512)           2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 7, 512)            0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 7, 128)            328192    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 7, 128)            131584    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,318,531\n",
      "Trainable params: 3,317,187\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_LSTM_model = tf.keras.Sequential([\n",
    "    Conv1D(16, 10, activation='relu', input_shape=(700, 1)),\n",
    "    Conv1D(16, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    \n",
    "    Conv1D(32, 10,activation='relu'),\n",
    "    Conv1D(32, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    \n",
    "    Conv1D(64, 10,activation='relu'),\n",
    "    Conv1D(64, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(128, 10,activation='relu'),\n",
    "    Conv1D(128, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Conv1D(256, 3,activation='relu'),\n",
    "    Conv1D(256, 3,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    Conv1D(512, 3,activation='relu'),\n",
    "    Conv1D(512, 3,activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    LSTM(128, return_sequences=True, input_shape=(700,1)),\n",
    "    Dropout(0.5),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(256),\n",
    "    \n",
    "    Dense(512, activation='LeakyReLU'),\n",
    "    Dense(1024, activation='LeakyReLU'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial settings\n",
    "Data = \"D:/Database/WESAD/\"\n",
    "sampling_rate = 700\n",
    "n_split = 5 # num of Fold\n",
    "random_state = 42\n",
    "subjects = np.array(['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17'])\n",
    "accuracies = [] # Fold accuracy list\n",
    "fold_i = 0\n",
    "\n",
    "# K-fold Code start\n",
    "kf = KFold(n_splits=n_split, shuffle=True, random_state=random_state)\n",
    "\n",
    "for train_index, test_index in kf.split(subjects):\n",
    "    \n",
    "    fold_i += 1\n",
    "    print(fold_i, '번째 검증')\n",
    "    \n",
    "    train_subjects, test_subjects = subjects[train_index], subjects[test_index]\n",
    "    \n",
    "    # Train Data load\n",
    "    train_data, train_labels = load_data(train_subjects)\n",
    "    # Test Data load\n",
    "    test_data, test_labels = load_data(test_subjects)\n",
    "    \n",
    "    # One-hot Encoding\n",
    "    train_y = to_categorical(train_labels)\n",
    "    test_y = to_categorical(test_labels)\n",
    "    \n",
    "    print('Train:', train_index, 'Test', test_index)\n",
    "    \n",
    "    # Model Training \n",
    "    model_clone = clone_model(CNN_LSTM_model)\n",
    "    model_clone.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model_clone.fit(train_data, train_y, epochs=50, batch_size=32) \n",
    "    scores = model_clone.evaluate(test_data, test_y)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_clone.predict(test_data)\n",
    "    Plot_confusion_matrix(test_y, pred)\n",
    "    \n",
    "    \n",
    "    accuracies.append(scores[1])\n",
    "    \n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print('평균 정확도 : ', average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef6878",
   "metadata": {},
   "source": [
    "# CNN-LSTM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "af1955ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_72 (Conv1D)          (None, 691, 128)          1408      \n",
      "                                                                 \n",
      " conv1d_73 (Conv1D)          (None, 682, 128)          163968    \n",
      "                                                                 \n",
      " max_pooling1d_31 (MaxPoolin  (None, 341, 128)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_74 (Conv1D)          (None, 332, 256)          327936    \n",
      "                                                                 \n",
      " conv1d_75 (Conv1D)          (None, 323, 256)          655616    \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 161, 256)         0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 161, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 161, 256)          0         \n",
      "                                                                 \n",
      " conv1d_76 (Conv1D)          (None, 152, 512)          1311232   \n",
      "                                                                 \n",
      " conv1d_77 (Conv1D)          (None, 143, 512)          2621952   \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 71, 512)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 71, 128)           328192    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 71, 128)           0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 71, 128)           131584    \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 71, 128)           0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 256)               394240    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,597,123\n",
      "Trainable params: 6,596,611\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN_LSTM2 = tf.keras.Sequential([\n",
    "    Conv1D(128, 10, activation='relu', input_shape=(700, 1)),\n",
    "    Conv1D(128, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    \n",
    "    \n",
    "    Conv1D(256, 10,activation='relu'),\n",
    "    Conv1D(256, 10,activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    \n",
    "    Conv1D(512, 10,activation='relu'),\n",
    "    Conv1D(512, 10,activation='relu'),\n",
    "    MaxPooling1D(2),  \n",
    "    \n",
    "    LSTM(128, return_sequences=True, input_shape=(700,1)),\n",
    "    Dropout(0.5),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(256),\n",
    "    \n",
    "    Dense(512, activation='LeakyReLU'),\n",
    "    Dense(1024, activation='LeakyReLU'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_LSTM2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d110719",
   "metadata": {},
   "source": [
    "# CNN-LSTM 5-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3734a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial settings\n",
    "Data = \"D:/Database/WESAD/\"\n",
    "sampling_rate = 700\n",
    "n_split = 5 # num of Fold\n",
    "random_state = 42\n",
    "subjects = np.array(['S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S13', 'S14', 'S15', 'S16', 'S17'])\n",
    "accuracies = [] # Fold accuracy list\n",
    "fold_i = 0\n",
    "\n",
    "# K-fold Code start\n",
    "kf = KFold(n_splits=n_split, shuffle=True, random_state=random_state)\n",
    "\n",
    "for train_index, test_index in kf.split(subjects):\n",
    "    \n",
    "    fold_i += 1\n",
    "    print(fold_i, '번째 검증')\n",
    "    \n",
    "    train_subjects, test_subjects = subjects[train_index], subjects[test_index]\n",
    "    \n",
    "    # Train Data load\n",
    "    train_data, train_labels = load_data(train_subjects)\n",
    "    # Test Data load\n",
    "    test_data, test_labels = load_data(test_subjects)\n",
    "    \n",
    "    # One-hot Encoding\n",
    "    train_y = to_categorical(train_labels)\n",
    "    test_y = to_categorical(test_labels)\n",
    "    \n",
    "    print('Train:', train_index, 'Test', test_index)\n",
    "    \n",
    "    # Model Training \n",
    "    model_clone = clone_model(CNN_LSTM2)\n",
    "    model_clone.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model_clone.fit(train_data, train_y, epochs=50, batch_size=32) \n",
    "    scores = model_clone.evaluate(test_data, test_y)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_clone.predict(test_data)\n",
    "    Plot_confusion_matrix(test_y, pred)\n",
    "    \n",
    "    \n",
    "    accuracies.append(scores[1])\n",
    "    \n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print('평균 정확도 : ', average_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg1",
   "language": "python",
   "name": "ecg1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
