{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d826ec-dae7-4e5f-9b29-32ead0bd1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Conv1D,TimeDistributed, Reshape, Activation, add, Layer, Concatenate, GRU, Bidirectional \n",
    "from tensorflow.keras.layers import MaxPooling1D, BatchNormalization, Dropout,Activation, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9901d135-83aa-4957-84fe-17437f56595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-peak detection\n",
    "def get_rpeak(signal, sampling_rate):\n",
    "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "    \n",
    "    return rpeaks['ECG_R_Peaks']\n",
    "\n",
    "# Segmentation Function\n",
    "\n",
    "def load_BEAT_data(signal, r_peaks):\n",
    "    signal_list = []\n",
    "    for number in range(1,len(r_peaks)-1):\n",
    "        signal_list.append(signal[r_peaks[number]-(int(left_sec*sampling_rate)) : r_peaks[number]+(int(right_sec*sampling_rate))])\n",
    "    return np.array(signal_list)\n",
    "\n",
    "def load_RHYTHM_data(data, rpeak, window):\n",
    "    rhythm_data = []\n",
    "    right = int(right_sec * sampling_rate)\n",
    "    for i in range(1,len(rpeak)-1):\n",
    "        if len(data[rpeak[i] + right : rpeak[i] + window + right]) == window:\n",
    "            rhythm_data.append(data[rpeak[i] + right : rpeak[i]+right + window])\n",
    "            \n",
    "    return np.array(rhythm_data)\n",
    "\n",
    "def load_WESAD(person, segment, window=0): \n",
    "    \n",
    "    excitement_data, baseline_data, stress_data, meditation_data = [], [], [], []\n",
    "    \n",
    "    for i in person:\n",
    "        df = pd.read_pickle(data_path + i + '.pkl')\n",
    "        print(f\"================== person = {i} ===========================\")\n",
    "\n",
    "        ex = df['excitement'].flatten()\n",
    "        base = df['baseline'].flatten()\n",
    "        stress = df['stress'].flatten()\n",
    "        medi = df['meditation'].flatten()\n",
    "\n",
    "        ex_r = get_rpeak(ex, sampling_rate)\n",
    "        base_r = get_rpeak(base, sampling_rate)\n",
    "        stress_r = get_rpeak(stress, sampling_rate)\n",
    "        medi_r = get_rpeak(medi, sampling_rate)\n",
    "\n",
    "        if segment == 'rhythm':\n",
    "            excitement_data.append(load_RHYTHM_data(ex, ex_r, window)) \n",
    "            baseline_data.append(load_RHYTHM_data(base, base_r, window)) \n",
    "            stress_data.append(load_RHYTHM_data(stress, stress_r, window)) \n",
    "            meditation_data.append(load_RHYTHM_data(medi, medi_r, window)) \n",
    "        else :\n",
    "            excitement_data.append(load_BEAT_data(ex, ex_r)) \n",
    "            baseline_data.append(load_BEAT_data(base, base_r)) \n",
    "            stress_data.append(load_BEAT_data(stress, stress_r)) \n",
    "            meditation_data.append(load_BEAT_data(medi, medi_r)) \n",
    "            \n",
    "    Amuse = np.vstack(excitement_data)\n",
    "    Base = np.vstack(baseline_data)\n",
    "    Stress = np.vstack(stress_data)\n",
    "    Meditation = np.vstack(meditation_data)\n",
    "    \n",
    "    amuse_label = np.zeros(Amuse.shape[0], np.int32)\n",
    "    normal_label = np.ones(Base.shape[0], np.int32)\n",
    "    stress_label = 2*np.ones(Stress.shape[0], np.int32)\n",
    "    meditation_label = 3*np.ones(Meditation.shape[0], np.int32)\n",
    "    \n",
    "    Train = np.concatenate([Amuse, Base, Stress, Meditation])\n",
    "    Train_label = np.concatenate([amuse_label, normal_label, stress_label, meditation_label])\n",
    "    \n",
    "    return Train, Train_label\n",
    "\n",
    "def shuffle_data2(data1, data2, labels):\n",
    "    # data1, data2, label을 입력받아 무작위로 섞고 (인덱스 위치는 동일하게) Return\n",
    "    indices = np.arange(data1.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data1[indices], data2[indices], labels[indices]\n",
    "\n",
    "def shuffle_data(data, labels):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data[indices], labels[indices]\n",
    "\n",
    "\n",
    "def Plot_lr_curve(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy'] \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "def Plot_confusion_matrix(true_d, pred, class_name):\n",
    "    \n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        pred_label.append(np.argmax(pred[i]))\n",
    "        \n",
    "    for i in range(len(true_d)):\n",
    "        true_label.append(np.argmax(true_d[i]))\n",
    "    \n",
    "    print(pred_label[0:10])\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_label, pred_label)\n",
    "    print('accuracy : ', np.round(accuracy,3))\n",
    "    \n",
    "    # Precision\n",
    "    precision = precision_score(true_label, pred_label, average='macro')\n",
    "    print('precision : ', np.round(precision,3))\n",
    "    \n",
    "    # Recall\n",
    "    recall = recall_score(true_label, pred_label,average='macro')\n",
    "    print('recall : ', np.round(recall,3))\n",
    "    \n",
    "    # F1 Score\n",
    "    F1_score = f1_score(true_label, pred_label,average='macro')\n",
    "    print('F1_score : ', np.round(F1_score,3))\n",
    "\n",
    "    #clasification report\n",
    "    report = classification_report(true_label, pred_label, target_names=class_name)#'Amuse',\n",
    "    print(report)\n",
    "    \n",
    "    #confusion matrix\n",
    "    confusion = confusion_matrix(true_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion, display_labels=class_name)#'Amuse',\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.figure(figsize=(10,5))\n",
    "    cmn = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=class_name, yticklabels=class_name)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94413adc-06b1-4196-92b3-7bfca26ff758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(person, beat, rhythm, window):\n",
    "        rhythm_train, rhythm_label = load_WESAD(person, 'rhythm', window)\n",
    "        beat_train, beat_label = load_WESAD(person, 'beat', window)\n",
    "        \n",
    "        beat_train = beat_train[:rhythm_train.shape[0]]\n",
    "        beat_label = beat_label[:rhythm_label.shape[0]]\n",
    "        \n",
    "        train_beat, train_rhythm, train_y = shuffle_data2(beat_train, rhythm_train, beat_label)\n",
    "        \n",
    "        return train_beat, train_rhythm, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f71f2-57a0-4361-a65d-2e09d8765e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_weight(label):\n",
    "    \n",
    "    counts = np.bincount(label)\n",
    "    \n",
    "    amuse_num = counts[0]\n",
    "    normal_num = counts[1]\n",
    "    stress_num = counts[2]\n",
    "    meditation_num = counts[3]\n",
    "    total = amuse_num + normal_num + stress_num + meditation_num\n",
    "    \n",
    "    weight_amuse = (1/amuse_num) * (total/4.0)\n",
    "    weight_normal = (1/normal_num) * (total/4.0)\n",
    "    weight_stress = (1/stress_num) * (total/4.0)\n",
    "    weight_meditation  = (1/meditation_num) * (total/4.0)\n",
    "    class_weight = {0:weight_amuse, 1:weight_normal, 2:weight_stress, 3:weight_meditation}\n",
    "    # print(total, class_weight)\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "from  tensorflow.keras.initializers import HeNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def scheuler(epoch, lr):\n",
    "    if epoch < 40:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "\n",
    "\n",
    "# 가중치 초기화 \n",
    "weight_init = HeNormal(seed= 128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7bb3a-8187-41a0-ac49-4e3904b6d076",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\Journal\\WESAD_Denoise_Outlier_Normalization_DB/\"\n",
    "data_path = data_path.replace('\\\\', '/')\n",
    "\n",
    "np.random.seed(128)\n",
    "random_state = 128\n",
    "\n",
    "sampling_rate = 700\n",
    "n_split = 5\n",
    "left_sec = 0.24\n",
    "right_sec = 0.4\n",
    "\n",
    "person = np.array(['S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S13','S14','S15','S16','S17'])\n",
    "class_name = np.array(['Amusement', 'Baseline', 'Stress','Meditation'])\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Fusion_Method/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4eab4b-4a23-4dc5-bf96-560b7f4ddbe8",
   "metadata": {},
   "source": [
    "# Average 5 Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1b54f-670f-4d17-b215-83827cb8d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    #fusion\n",
    "    #concatenated = Concatenate()([GAP_B, GAP_R])\n",
    "    Average_layer = Average()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Average_layer.shape[1]))(Average_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0580303-599c-4318-88f5-1f67aeac8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = sampling_rate * 3\n",
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e943e9-dd28-4cdd-a779-98607683ecbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Fusion_Method/\"\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Average_Fusion_5_layer(8,2)(0.0001)_3s_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb239aec-d78c-4ee2-827c-235a95994523",
   "metadata": {},
   "source": [
    "# Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bacde9-34ff-44f6-a2a5-70b5ad5c83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Maximum(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    maximum_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, maximum_layer.shape[1]))(maximum_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441917a-5f71-4ed0-8ffd-e9c97010f169",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Maximum(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Maximum_Fusion_5_layer(8,2)(0.0001)_3s_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda22087-a861-48d7-a66a-a98d9a0acb0a",
   "metadata": {},
   "source": [
    "# Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73545d0c-bc1e-445d-916a-c3025f6001e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Multimply(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    multiply_layer = Multiply()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, multiply_layer.shape[1]))(multiply_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5733db-be39-4ac5-a68f-728035fd97b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Multimply(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Multiply_Fusion_5_layer(8,2)(0.0001)_3s_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb2e9d-c42c-4122-80b1-89afb10a2b00",
   "metadata": {},
   "source": [
    "# Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de164ec-0265-453a-aba8-a7ef6ed6ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = Add()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afddaf-9151-4deb-8f1c-178fd449b9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Add_Fusion_5_layer_3s_(0.0001)_Fold(8,2)_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00b78d-35e0-493b-aa6a-439bdc65ec9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ddd95-5829-499b-a93a-54224877f635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f64b62-ba3f-4d4a-89f6-7422e0e0da9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72763c-5dfb-48c4-80ee-bb278608b27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b6889-50cb-46a5-8af2-6cbf7eea759a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32cd451f-45e1-4d68-a48a-bb29996897f0",
   "metadata": {},
   "source": [
    "# 6 layer and 8 seoncd Fusion method 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0e45d-1f50-45dd-8ba7-5f5f46585fc7",
   "metadata": {},
   "source": [
    "# Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62cb60-0150-41bc-b88f-847fe9d371dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    conv1_R_5 = Conv1D(128, 1, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(conv1_R_5)\n",
    "\n",
    "    #fusion\n",
    "    Average_layer = Average()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Average_layer.shape[1]))(Average_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d895287-5820-49b8-a755-4f351f179d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = sampling_rate * 8\n",
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109015d-64f5-4242-82cf-872e5d821ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Fusion_Method/\"\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + '2_Average_Fusion_6_layer_8s_Fold(8,2)_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae522c74-1c90-4917-a4c8-86a3d9a6d13c",
   "metadata": {},
   "source": [
    "# Maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd155d-6f1b-42fa-bc79-b6b40f98c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Maximum(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    conv1_R_5 = Conv1D(128, 1, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(conv1_R_5)\n",
    "\n",
    "    # Fusion\n",
    "    maximum_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, maximum_layer.shape[1]))(maximum_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451663f-73c6-48bc-a26e-a8f1550fb23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"D:/Journal/WESAD_Model/Fusion_Method/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aa2c3-5113-45c7-a6fc-e0941062ffd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Maximum(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + '2_Maximum_Fusion_6_layer_8s_Fold(8,2)_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5d45b-c222-4dfc-83dd-dc14a5f68bbe",
   "metadata": {},
   "source": [
    "# Multipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5f171-d6f3-4d61-90a2-fff97e113c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Multimply(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    conv1_R_5 = Conv1D(128, 1, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(conv1_R_5)\n",
    "\n",
    "    # Fusion\n",
    "    multiply_layer = Multiply()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, multiply_layer.shape[1]))(multiply_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8291ea-716d-4b15-b182-16785067a0e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Multimply(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + '2_Multiply_Fusion_6_layer_8s_Fold(8,2)_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca569f-d1f5-4753-8488-0ee25511b18e",
   "metadata": {},
   "source": [
    "# Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082701d-4d04-4b6b-a5ad-2b73514b3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    conv1_R_5 = Conv1D(128, 1, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(conv1_R_5)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = Add()([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2befd-ceea-49fe-a5d2-121267e64a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + '2_Add_Fusion_6_layer_8s_Fold(8,2)_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab881563-75c9-4394-a43d-aa74e1fc74df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfdb010-2b2f-4d5a-ab1c-d0d6d714213d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba50fa5-d4aa-4f60-9b34-7b9814247188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738442f1-cbef-44c2-acc3-7b759844288a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_research",
   "language": "python",
   "name": "ecg1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
