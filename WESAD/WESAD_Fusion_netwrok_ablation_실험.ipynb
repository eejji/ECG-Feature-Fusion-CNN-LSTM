{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ca394-8abd-407d-877f-5c7206fbc7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Conv1D,TimeDistributed, Reshape, Activation, add, Layer, Concatenate, GRU, Bidirectional \n",
    "from tensorflow.keras.layers import MaxPooling1D, BatchNormalization, Dropout,Activation, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e075729-d824-439b-8983-15fe2bb2d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-peak detection\n",
    "def get_rpeak(signal, sampling_rate):\n",
    "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "    \n",
    "    return rpeaks['ECG_R_Peaks']\n",
    "\n",
    "# Segmentation Function\n",
    "\n",
    "def load_BEAT_data(signal, r_peaks):\n",
    "    signal_list = []\n",
    "    for number in range(1,len(r_peaks)-1):\n",
    "        signal_list.append(signal[r_peaks[number]-(int(left_sec*sampling_rate)) : r_peaks[number]+(int(right_sec*sampling_rate))])\n",
    "    return np.array(signal_list)\n",
    "\n",
    "def load_RHYTHM_data(data, rpeak, window):\n",
    "    rhythm_data = []\n",
    "    right = int(right_sec * sampling_rate)\n",
    "    for i in range(1,len(rpeak)-1):\n",
    "        if len(data[rpeak[i] + right : rpeak[i] + window + right]) == window:\n",
    "            rhythm_data.append(data[rpeak[i] + right : rpeak[i]+right + window])\n",
    "            \n",
    "    return np.array(rhythm_data)\n",
    "\n",
    "def load_WESAD(person, segment, window=0): \n",
    "    \n",
    "    excitement_data, baseline_data, stress_data, meditation_data = [], [], [], []\n",
    "    \n",
    "    for i in person:\n",
    "        df = pd.read_pickle(data_path + i + '.pkl')\n",
    "        print(f\"================== person = {i} ===========================\")\n",
    "\n",
    "        ex = df['excitement'].flatten()\n",
    "        base = df['baseline'].flatten()\n",
    "        stress = df['stress'].flatten()\n",
    "        medi = df['meditation'].flatten()\n",
    "\n",
    "        ex_r = get_rpeak(ex, sampling_rate)\n",
    "        base_r = get_rpeak(base, sampling_rate)\n",
    "        stress_r = get_rpeak(stress, sampling_rate)\n",
    "        medi_r = get_rpeak(medi, sampling_rate)\n",
    "\n",
    "        if segment == 'rhythm':\n",
    "            excitement_data.append(load_RHYTHM_data(ex, ex_r, window)) \n",
    "            baseline_data.append(load_RHYTHM_data(base, base_r, window)) \n",
    "            stress_data.append(load_RHYTHM_data(stress, stress_r, window)) \n",
    "            meditation_data.append(load_RHYTHM_data(medi, medi_r, window)) \n",
    "        else :\n",
    "            excitement_data.append(load_BEAT_data(ex, ex_r)) \n",
    "            baseline_data.append(load_BEAT_data(base, base_r)) \n",
    "            stress_data.append(load_BEAT_data(stress, stress_r)) \n",
    "            meditation_data.append(load_BEAT_data(medi, medi_r)) \n",
    "            \n",
    "    Amuse = np.vstack(excitement_data)\n",
    "    Base = np.vstack(baseline_data)\n",
    "    Stress = np.vstack(stress_data)\n",
    "    Meditation = np.vstack(meditation_data)\n",
    "    \n",
    "    amuse_label = np.zeros(Amuse.shape[0], np.int32)\n",
    "    normal_label = np.ones(Base.shape[0], np.int32)\n",
    "    stress_label = 2*np.ones(Stress.shape[0], np.int32)\n",
    "    meditation_label = 3*np.ones(Meditation.shape[0], np.int32)\n",
    "    \n",
    "    Train = np.concatenate([Amuse, Base, Stress, Meditation])\n",
    "    Train_label = np.concatenate([amuse_label, normal_label, stress_label, meditation_label])\n",
    "    \n",
    "    return Train, Train_label\n",
    "\n",
    "def shuffle_data2(data1, data2, labels):\n",
    "    # data1, data2, label을 입력받아 무작위로 섞고 (인덱스 위치는 동일하게) Return\n",
    "    indices = np.arange(data1.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data1[indices], data2[indices], labels[indices]\n",
    "\n",
    "def shuffle_data(data, labels):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data[indices], labels[indices]\n",
    "\n",
    "\n",
    "def Plot_lr_curve(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy'] \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "def Plot_confusion_matrix(true_d, pred, class_name):\n",
    "    \n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        pred_label.append(np.argmax(pred[i]))\n",
    "        \n",
    "    for i in range(len(true_d)):\n",
    "        true_label.append(np.argmax(true_d[i]))\n",
    "    \n",
    "    print(pred_label[0:10])\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_label, pred_label)\n",
    "    print('accuracy : ', np.round(accuracy,3))\n",
    "    \n",
    "    # Precision\n",
    "    precision = precision_score(true_label, pred_label, average='macro')\n",
    "    print('precision : ', np.round(precision,3))\n",
    "    \n",
    "    # Recall\n",
    "    recall = recall_score(true_label, pred_label,average='macro')\n",
    "    print('recall : ', np.round(recall,3))\n",
    "    \n",
    "    # F1 Score\n",
    "    F1_score = f1_score(true_label, pred_label,average='macro')\n",
    "    print('F1_score : ', np.round(F1_score,3))\n",
    "\n",
    "    #clasification report\n",
    "    report = classification_report(true_label, pred_label, target_names=class_name)#'Amuse',\n",
    "    print(report)\n",
    "    \n",
    "    #confusion matrix\n",
    "    confusion = confusion_matrix(true_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion, display_labels=class_name)#'Amuse',\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.figure(figsize=(10,5))\n",
    "    cmn = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=class_name, yticklabels=class_name)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5331693-d86d-4b56-b252-930337e3b3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(person, beat, rhythm, window):\n",
    "        rhythm_train, rhythm_label = load_WESAD(person, 'rhythm', window)\n",
    "        beat_train, beat_label = load_WESAD(person, 'beat', window)\n",
    "        \n",
    "        beat_train = beat_train[:rhythm_train.shape[0]]\n",
    "        beat_label = beat_label[:rhythm_label.shape[0]]\n",
    "        \n",
    "        train_beat, train_rhythm, train_y = shuffle_data2(beat_train, rhythm_train, beat_label)\n",
    "        \n",
    "        return train_beat, train_rhythm, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c4d87-2ab3-4334-b7e1-4b47e56db33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_weight(label):\n",
    "    \n",
    "    counts = np.bincount(label)\n",
    "    \n",
    "    amuse_num = counts[0]\n",
    "    normal_num = counts[1]\n",
    "    stress_num = counts[2]\n",
    "    meditation_num = counts[3]\n",
    "    total = amuse_num + normal_num + stress_num + meditation_num\n",
    "    \n",
    "    weight_amuse = (1/amuse_num) * (total/4.0)\n",
    "    weight_normal = (1/normal_num) * (total/4.0)\n",
    "    weight_stress = (1/stress_num) * (total/4.0)\n",
    "    weight_meditation  = (1/meditation_num) * (total/4.0)\n",
    "    class_weight = {0:weight_amuse, 1:weight_normal, 2:weight_stress, 3:weight_meditation}\n",
    "    # print(total, class_weight)\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "from  tensorflow.keras.initializers import HeNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def scheuler(epoch, lr):\n",
    "    if epoch < 40:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "\n",
    "\n",
    "# 가중치 초기화 \n",
    "weight_init = HeNormal(seed= 128)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead69de-0970-48e2-bae7-a25b69e368d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\Journal\\WESAD_Denoise_Outlier_Normalization_DB/\"\n",
    "data_path = data_path.replace('\\\\', '/')\n",
    "\n",
    "np.random.seed(128)\n",
    "random_state = 128\n",
    "\n",
    "sampling_rate = 700\n",
    "n_split = 5\n",
    "left_sec = 0.24\n",
    "right_sec = 0.4\n",
    "\n",
    "person = np.array(['S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S13','S14','S15','S16','S17'])\n",
    "class_name = np.array(['Amusement', 'Baseline', 'Stress','Meditation'])\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Benchmark_model_ablation/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625cc5dc-33aa-44ad-a605-924dab8935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = sampling_rate * 3\n",
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a107b8-d57e-43f2-93e7-51213d84587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    # x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bef2d5-2157-45de-b0f3-1cba73d20207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_1_LSTM_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e836627-d4f8-4b6f-afbe-4d1c82ee7ec6",
   "metadata": {},
   "source": [
    "#  CNN-GRU 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8e0a1-0852-4899-8cdb-ec8db03c11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = GRU(128,return_sequences=True)(re_R)\n",
    "    # x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e811333-26d9-41c5-9bbe-0d9b82cbb794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_1_GRU_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0a777-f809-4109-8088-a72236ff0f66",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d52d7d-48ce-4669-9be4-5ad287d21602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = Bidirectional(LSTM(128,return_sequences=True))(re_R)\n",
    "    # x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8e9ff-cee7-4ca6-917f-fb32c392f74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_1_Bi-LSTM_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ce3c9-ac12-4e1c-b6df-9ca4e0ac5d8f",
   "metadata": {},
   "source": [
    "# Bi-GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7deb5-e7e6-466b-b7c5-1fd121025e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = Bidirectional(GRU(128,return_sequences=True))(re_R)\n",
    "    # x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e419afd-c07b-4635-bdaa-9a571f9e7ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_1_Bi-GRU_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf4d8e-346c-48a1-89b5-d88c27dcaa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2322275b-2982-45e7-8930-f2bdbec46c04",
   "metadata": {},
   "source": [
    "# CNN-GRU 2layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15c73b-c2e6-4f06-b2ad-d5949844981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = GRU(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = GRU(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a77b5-5ffe-43fc-9d4a-1420a3faa142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_2_GRU_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ffe595-baab-481a-8b32-fc09e474f7c9",
   "metadata": {},
   "source": [
    "# CNN-BiLSTM 2layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c78a2-62ad-4a93-9025-1f73af875e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = Bidirectional(LSTM(128,return_sequences=True))(re_R)\n",
    "    x_R_LSTM2 = Bidirectional(LSTM(64, return_sequences=True))(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c092bf9-ff42-42ab-befd-aab49da2dec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_2_Bi-LSTM_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d8d73-0e62-441f-9ae2-632bc47701b7",
   "metadata": {},
   "source": [
    "# CNN-BiGRU 2 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886654e3-4b01-46a0-a6fd-d756a8a007d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Average, maximum, Multiply, Add, dot\n",
    "\n",
    "\n",
    "def WESAD_fusion_model_Add(re_X_train_b, re_X_train_r):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_3 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3) \n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_3)\n",
    "\n",
    "    # Rhythm\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    # Fusion\n",
    "    Add_layer = maximum([GAP_B, GAP_R])\n",
    "\n",
    "    re_R = Reshape((1, Add_layer.shape[1]))(Add_layer)\n",
    "    x_R_LSTM = Bidirectional(GRU(128,return_sequences=True))(re_R)\n",
    "    x_R_LSTM2 = Bidirectional(GRU(64, return_sequences=True))(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=[input_beat, input_rhythm], outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1968168-1b96-404b-b7e1-acef175c0d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "number=1\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    print('=========================================__Fold__'+str(number)+'_______=================================')\n",
    "    X_train_b, X_test_b, X_train_r, X_test_r = train_beat[train_index], train_beat[test_index], train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)    \n",
    "    class_weight = cal_class_weight(train_y)\n",
    "\n",
    "    \n",
    "    fusion_model = WESAD_fusion_model_Add(X_train_b.shape[1], X_train_r.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    fusion_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = fusion_model.fit([X_train_b, X_train_r], y_train, \n",
    "                        validation_data=([X_test_b, X_test_r], y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        class_weight = class_weight,\n",
    "                        callbacks=[callback_lr],\n",
    "                       ) \n",
    "\n",
    "    \n",
    "    scores = fusion_model.evaluate([X_test_b,X_test_r], y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = fusion_model.predict([X_test_b,X_test_r])\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "\n",
    "    \n",
    "    fusion_model.save(save_model_path + 'Fusion_network(Maximum)(8,2)(0.0001)_2_Bi-GRU_layer_Fold_'  +str(number)+ '_(' + str(np.round(scores[1]*100,2)) + ').h5')\n",
    "    number+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ba2d6-9ea8-449a-847a-05826a8c47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebd642-7d8b-4605-ac36-e14e7a2721ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a38fa-1a50-47d4-8c13-529f47bb273d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920db280-4863-4e59-808e-70c921455204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a702d-f184-43e9-81a9-e09d9897f3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba0940-7216-4e8b-96c4-7120e6565b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1232b8-9a3d-41af-a205-21ba1a347277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9aea09-586b-4caa-ad4c-4af8671548ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b08166-fd95-4db4-a758-77e39fcbae62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442b858-e14d-436d-b02a-7d6afb5774e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ffc40-c35d-487e-aa0b-5cf11941e0df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ccc53-62c5-43d8-b768-b8801f455e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee100d34-8759-4108-9c6c-6c79310144f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b538345-f1fb-48b3-a2ff-dd4822a5bdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bfe19f-0d34-48e7-af93-7dffb699ccf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_research",
   "language": "python",
   "name": "ecg1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
