{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9eca9d-d4fe-4d41-a920-28bee6bbb054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Conv1D,TimeDistributed, Reshape, Activation, add, Layer, Concatenate, GRU, Bidirectional \n",
    "from tensorflow.keras.layers import MaxPooling1D, BatchNormalization, Dropout,Activation, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead747f-adf9-4d1d-a760-b1b09055741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-peak detection\n",
    "def get_rpeak(signal, sampling_rate):\n",
    "    _, rpeaks = nk.ecg_peaks(signal, sampling_rate=sampling_rate, show=False, method='neurokit')\n",
    "    \n",
    "    return rpeaks['ECG_R_Peaks']\n",
    "\n",
    "# Segmentation Function\n",
    "\n",
    "def load_BEAT_data(signal, r_peaks):\n",
    "    signal_list = []\n",
    "    for number in range(1,len(r_peaks)-1):\n",
    "        signal_list.append(signal[r_peaks[number]-(int(left_sec*sampling_rate)) : r_peaks[number]+(int(right_sec*sampling_rate))])\n",
    "    return np.array(signal_list)\n",
    "\n",
    "def load_RHYTHM_data(data, rpeak, window):\n",
    "    rhythm_data = []\n",
    "    right = int(right_sec * sampling_rate)\n",
    "    for i in range(1,len(rpeak)-1):\n",
    "        if len(data[rpeak[i] + right : rpeak[i] + window + right]) == window:\n",
    "            rhythm_data.append(data[rpeak[i] + right : rpeak[i]+right + window])\n",
    "            \n",
    "    return np.array(rhythm_data)\n",
    "\n",
    "def load_WESAD(person, segment, window=0): \n",
    "    \n",
    "    excitement_data, baseline_data, stress_data, meditation_data = [], [], [], []\n",
    "    \n",
    "    for i in person:\n",
    "        df = pd.read_pickle(data_path + i + '.pkl')\n",
    "        print(f\"================== person = {i} ===========================\")\n",
    "\n",
    "        ex = df['excitement'].flatten()\n",
    "        base = df['baseline'].flatten()\n",
    "        stress = df['stress'].flatten()\n",
    "        medi = df['meditation'].flatten()\n",
    "\n",
    "        ex_r = get_rpeak(ex, sampling_rate)\n",
    "        base_r = get_rpeak(base, sampling_rate)\n",
    "        stress_r = get_rpeak(stress, sampling_rate)\n",
    "        medi_r = get_rpeak(medi, sampling_rate)\n",
    "\n",
    "        if segment == 'rhythm':\n",
    "            excitement_data.append(load_RHYTHM_data(ex, ex_r, window)) \n",
    "            baseline_data.append(load_RHYTHM_data(base, base_r, window)) \n",
    "            stress_data.append(load_RHYTHM_data(stress, stress_r, window)) \n",
    "            meditation_data.append(load_RHYTHM_data(medi, medi_r, window)) \n",
    "        else :\n",
    "            excitement_data.append(load_BEAT_data(ex, ex_r)) \n",
    "            baseline_data.append(load_BEAT_data(base, base_r)) \n",
    "            stress_data.append(load_BEAT_data(stress, stress_r)) \n",
    "            meditation_data.append(load_BEAT_data(medi, medi_r)) \n",
    "            \n",
    "    Amuse = np.vstack(excitement_data)\n",
    "    Base = np.vstack(baseline_data)\n",
    "    Stress = np.vstack(stress_data)\n",
    "    Meditation = np.vstack(meditation_data)\n",
    "    \n",
    "    amuse_label = np.zeros(Amuse.shape[0], np.int32)\n",
    "    normal_label = np.ones(Base.shape[0], np.int32)\n",
    "    stress_label = 2*np.ones(Stress.shape[0], np.int32)\n",
    "    meditation_label = 3*np.ones(Meditation.shape[0], np.int32)\n",
    "    \n",
    "    Train = np.concatenate([Amuse, Base, Stress, Meditation])\n",
    "    Train_label = np.concatenate([amuse_label, normal_label, stress_label, meditation_label])\n",
    "    \n",
    "    return Train, Train_label\n",
    "\n",
    "def shuffle_data2(data1, data2, labels):\n",
    "    # data1, data2, label을 입력받아 무작위로 섞고 (인덱스 위치는 동일하게) Return\n",
    "    indices = np.arange(data1.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data1[indices], data2[indices], labels[indices]\n",
    "\n",
    "\n",
    "def Plot_lr_curve(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy'] \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "\n",
    "def Plot_confusion_matrix(true_d, pred, class_name):\n",
    "    \n",
    "    pred_label = []\n",
    "    true_label = []\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        pred_label.append(np.argmax(pred[i]))\n",
    "        \n",
    "    for i in range(len(true_d)):\n",
    "        true_label.append(np.argmax(true_d[i]))\n",
    "    \n",
    "    print(pred_label[0:10])\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(true_label, pred_label)\n",
    "    print('accuracy : ', np.round(accuracy,3))\n",
    "    \n",
    "    # Precision\n",
    "    precision = precision_score(true_label, pred_label, average='macro')\n",
    "    print('precision : ', np.round(precision,3))\n",
    "    \n",
    "    # Recall\n",
    "    recall = recall_score(true_label, pred_label,average='macro')\n",
    "    print('recall : ', np.round(recall,3))\n",
    "    \n",
    "    # F1 Score\n",
    "    F1_score = f1_score(true_label, pred_label,average='macro')\n",
    "    print('F1_score : ', np.round(F1_score,3))\n",
    "\n",
    "    #clasification report\n",
    "    report = classification_report(true_label, pred_label, target_names=class_name)#'Amuse',\n",
    "    print(report)\n",
    "    \n",
    "    #confusion matrix\n",
    "    confusion = confusion_matrix(true_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion, display_labels=class_name)#'Amuse',\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.figure(figsize=(10,5))\n",
    "    cmn = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=class_name, yticklabels=class_name)\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159c614-f4b7-49e5-b74f-0d8bca9afec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(person, beat, rhythm, window):\n",
    "        rhythm_train, rhythm_label = load_WESAD(person, 'rhythm', window)\n",
    "        beat_train, beat_label = load_WESAD(person, 'beat', window)\n",
    "        \n",
    "        beat_train = beat_train[:rhythm_train.shape[0]]\n",
    "        beat_label = beat_label[:rhythm_label.shape[0]]\n",
    "        \n",
    "        train_beat, train_rhythm, train_y = shuffle_data2(beat_train, rhythm_train, beat_label)\n",
    "        \n",
    "        return train_beat, train_rhythm, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b67c0e-7d4a-4a29-b2b9-b647a82b54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:\\Journal\\WESAD_Denoise_Outlier_Normalization_DB/\"\n",
    "data_path = data_path.replace('\\\\', '/')\n",
    "\n",
    "np.random.seed(128)\n",
    "random_state = 128\n",
    "\n",
    "sampling_rate = 700\n",
    "n_split = 5\n",
    "left_sec = 0.24\n",
    "right_sec = 0.4\n",
    "\n",
    "person = np.array(['S2','S3','S4','S5','S6','S7','S8','S9','S10','S11','S13','S14','S15','S16','S17'])\n",
    "class_name = np.array(['Amusement', 'Baseline', 'Stress','Meditation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4a0fc-dd37-442f-a6f0-3dd234b6a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list = [i*sampling_rate for i in range(2,11)]\n",
    "print(window_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b500e4-bcc2-4f5a-9679-8b1e5f1349c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', sampling_rate*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c5e76-544b-4e16-bd57-cbf0110da020",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Beat network 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52049023-88fc-4bcb-ae10-bf6c2228cf5d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558fa08-12a3-4338-91a1-e49bc78316ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.initializers import HeNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def scheuler(epoch, lr):\n",
    "    if epoch < 41:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "\n",
    "\n",
    "\n",
    "# 조기 종료 \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.005, restore_best_weights=True)\n",
    "\n",
    "# 가중치 초기화 \n",
    "weight_init = HeNormal(seed= 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9527fb3-4c02-4c27-85d9-c0a563582724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beat_model(re_X_train_b):\n",
    "    input_beat = Input(shape=(re_X_train_b,1), name = 'input_beat')\n",
    "\n",
    "    conv1_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_beat)\n",
    "    conv2_B = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B)\n",
    "    bn1_B = BatchNormalization()(conv2_B)\n",
    "    act_B = Activation('relu')(bn1_B)\n",
    "    max1_B = MaxPooling1D(2,2)(act_B)\n",
    "\n",
    "    conv1_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B)\n",
    "    conv2_B_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_1)\n",
    "    bn1_B_1 = BatchNormalization()(conv2_B_1)\n",
    "    act_B_1 = Activation('relu')(bn1_B_1)\n",
    "    max1_B_1 = MaxPooling1D(2,2)(act_B_1)\n",
    "\n",
    "\n",
    "    conv1_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_1)\n",
    "    conv2_B_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_2)\n",
    "    bn1_B_2 = BatchNormalization()(conv2_B_2)\n",
    "    act_B_2 = Activation('relu')(bn1_B_2)\n",
    "    max1_B_2 = MaxPooling1D(2,2)(act_B_2)\n",
    "\n",
    "    conv1_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_2)\n",
    "    conv2_B_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_3)\n",
    "    bn1_B_3 = BatchNormalization()(conv2_B_3)\n",
    "    act_B_3 = Activation('relu')(bn1_B_3)\n",
    "    max1_B_3 = MaxPooling1D(2,2)(act_B_3)\n",
    "\n",
    "    conv1_B_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_3)\n",
    "    conv2_B_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_4)\n",
    "    bn1_B_4 = BatchNormalization()(conv2_B_4)\n",
    "    act_B_4 = Activation('relu')(bn1_B_4)\n",
    "    max1_B_4 = MaxPooling1D(2,2)(act_B_4)\n",
    "\n",
    "    # conv1_B_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_4)\n",
    "    # conv2_B_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_5)\n",
    "    # bn1_B_5 = BatchNormalization()(conv2_B_5)\n",
    "    # act_B_5 = Activation('relu')(bn1_B_5)\n",
    "    # max1_B_5 = MaxPooling1D(2,2)(act_B_5)\n",
    "\n",
    "    # conv1_B_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_5)\n",
    "    # conv2_B_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_6)\n",
    "    # bn1_B_6 = BatchNormalization()(conv2_B_6)\n",
    "    # act_B_6 = Activation('relu')(bn1_B_6)\n",
    "    # max1_B_6 = MaxPooling1D(2,2)(act_B_6)\n",
    "\n",
    "    # conv1_B_7 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_B_6)\n",
    "    # conv2_B_7 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_B_7)\n",
    "    # bn1_B_7 = BatchNormalization()(conv2_B_7)\n",
    "    # act_B_7 = Activation('relu')(bn1_B_7)\n",
    "    # max1_B_7 = MaxPooling1D(2,2)(act_B_7)\n",
    "\n",
    "    GAP_B = GlobalAveragePooling1D()(max1_B_4)\n",
    "\n",
    "    re_R = Reshape((1, GAP_B.shape[1]))(GAP_B)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs=input_beat, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe9f72-435c-4608-af89-f67300dfcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts = np.sum(train, axis=0)\n",
    "counts = np.bincount(train_y)\n",
    "print(counts)\n",
    "\n",
    "amuse_num = counts[0]\n",
    "normal_num = counts[1]\n",
    "stress_num = counts[2]\n",
    "meditation_num = counts[3]\n",
    "total = amuse_num + normal_num + stress_num + meditation_num\n",
    "\n",
    "weight_amuse = (1/amuse_num) * (total/4.0)\n",
    "weight_normal = (1/normal_num) * (total/4.0)\n",
    "weight_stress = (1/stress_num) * (total/4.0)\n",
    "weight_meditation  = (1/meditation_num) * (total/4.0)\n",
    "class_weight = {0:weight_amuse, 1:weight_normal, 2:weight_stress, 3:weight_meditation}\n",
    "print(total, class_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef7b5b-a187-43a9-a8b7-7d1039ae7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_b, test_b, train_label, test_label = train_test_split(train_beat, train_y,\n",
    "                                                            test_size=0.2,\n",
    "                                                            stratify=train_y,\n",
    "                                                            random_state=128,\n",
    "                                                            shuffle=True)\n",
    "\n",
    "train_b, val_b, train_label, val_label = train_test_split(train_b, train_label,\n",
    "                                                         test_size=0.25,\n",
    "                                                         stratify=train_label,\n",
    "                                                         random_state=128,\n",
    "                                                         shuffle=True)\n",
    "\n",
    "print(train_b.shape, val_b.shape, test_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd5fe4-b6d4-4c92-907b-b645f3952f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = to_categorical(train_label)\n",
    "val_label = to_categorical(val_label)\n",
    "test_label = to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b8249-3b0c-4296-9a59-4e1ad2851eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b = beat_model(train_b.shape[1])\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "model_b.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping\n",
    "history = model_b.fit(train_b, train_label,\n",
    "                      validation_data=(val_b, val_label),\n",
    "                      epochs=200,\n",
    "                      batch_size=32,\n",
    "                      callbacks=[early_stopping],\n",
    "                      class_weight = class_weight\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aaebe6-2703-49cf-90f5-73f062de743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_b.evaluate(test_b, test_label)\n",
    "Plot_lr_curve(history)\n",
    "pred = model_b.predict(test_b)\n",
    "Plot_confusion_matrix(test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76d980-112c-489c-a47d-b3b73791edb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eebea1d-6e5d-42f5-8cd9-18d9eceb3b88",
   "metadata": {},
   "source": [
    "# Beat 학습률 0.0001 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5bdf0b-52fe-4ce2-8b70-9bd0b7c023d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def cal_class_weight(label):\n",
    "    \n",
    "    counts = np.bincount(label)\n",
    "    \n",
    "    amuse_num = counts[0]\n",
    "    normal_num = counts[1]\n",
    "    stress_num = counts[2]\n",
    "    meditation_num = counts[3]\n",
    "    total = amuse_num + normal_num + stress_num + meditation_num\n",
    "    \n",
    "    weight_amuse = (1/amuse_num) * (total/4.0)\n",
    "    weight_normal = (1/normal_num) * (total/4.0)\n",
    "    weight_stress = (1/stress_num) * (total/4.0)\n",
    "    weight_meditation  = (1/meditation_num) * (total/4.0)\n",
    "    class_weight = {0:weight_amuse, 1:weight_normal, 2:weight_stress, 3:weight_meditation}\n",
    "    # print(total, class_weight)\n",
    "\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef4571-34c3-4d9c-834b-35cb6d8c8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', sampling_rate*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665a2dc-30ab-4840-9c7e-0f4ecc997898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## layer 실험\n",
    "number = 1\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Beat_Rhythm_5Fold_실험/\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "\n",
    "for train_index, test_index in skf.split(train_beat, train_y):\n",
    "    X_train_b, X_test_b = train_beat[train_index], train_beat[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)\n",
    "    class_weight = cal_class_weight(Y_train)\n",
    "\n",
    "    MAUS_beat_model = beat_model(X_train_b.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    MAUS_beat_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = MAUS_beat_model.fit(X_train_b, y_train, \n",
    "                        validation_data=(X_test_b, y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        callbacks=[callback_lr],\n",
    "                        class_weight=class_weight\n",
    "                       ) \n",
    "    \n",
    "    \n",
    "    scores = MAUS_beat_model.evaluate(X_test_b, y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = MAUS_beat_model.predict(X_test_b)\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "    \n",
    "    \n",
    "    MAUS_beat_model.save(save_model_path + 'WESAD_beat_8020_(0.0001)_Fold_'  +str(number)+ '(' + str(np.round(scores[1]*100,2)) + ').h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ccd531-5e38-432b-ae2c-917cd4a65bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20d46843-149e-4be1-abd8-2f58783b2138",
   "metadata": {},
   "source": [
    "## Rhythm network 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7ddce-5139-44a6-b745-61ba8b70f1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c18f9-d296-4d91-a713-c1f042c020a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51801466-cab0-4f86-acd7-d166e5423117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tensorflow.keras.initializers import HeNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def scheuler(epoch, lr):\n",
    "    if epoch < 41:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "\n",
    "\n",
    "\n",
    "# 조기 종료 \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, min_delta=0.005, restore_best_weights=True)\n",
    "\n",
    "# 가중치 초기화 \n",
    "weight_init = HeNormal(seed= 128)\n",
    "\n",
    "#counts = np.sum(train, axis=0)\n",
    "\n",
    "def cal_class_weight(label):\n",
    "    \n",
    "    counts = np.bincount(label)\n",
    "    \n",
    "    amuse_num = counts[0]\n",
    "    normal_num = counts[1]\n",
    "    stress_num = counts[2]\n",
    "    meditation_num = counts[3]\n",
    "    total = amuse_num + normal_num + stress_num + meditation_num\n",
    "    \n",
    "    weight_amuse = (1/amuse_num) * (total/4.0)\n",
    "    weight_normal = (1/normal_num) * (total/4.0)\n",
    "    weight_stress = (1/stress_num) * (total/4.0)\n",
    "    weight_meditation  = (1/meditation_num) * (total/4.0)\n",
    "    class_weight = {0:weight_amuse, 1:weight_normal, 2:weight_stress, 3:weight_meditation}\n",
    "    # print(total, class_weight)\n",
    "\n",
    "    return class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb99f99-b3e8-47d6-a61e-868a8404bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(data, labels):\n",
    "    indices = np.arange(data.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    return data[indices], labels[indices]\n",
    "\n",
    "def load_data(person, rhythm, window):\n",
    "        rhythm_train, rhythm_label = load_WESAD(person, 'rhythm', window)\n",
    "        train_rhythm, train_y = shuffle_data(rhythm_train, rhythm_label)\n",
    "        \n",
    "        return train_rhythm, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c6885-cc0d-4b58-8317-c7795d8b11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    # conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    # conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    # bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    # act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    # max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    # conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    # conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    # bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    # act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    # max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    # conv1_R_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "    # conv2_R_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_6)\n",
    "    # bn1_R_6 = BatchNormalization()(conv2_R_6)\n",
    "    # act_R_6 = Activation('relu')(bn1_R_6)\n",
    "    # max1_R_6 = MaxPooling1D(2,2)(act_R_6)\n",
    "\n",
    "    # conv1_R_7 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_6)\n",
    "    # conv2_R_7 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_7)\n",
    "    # bn1_R_7 = BatchNormalization()(conv2_R_7)\n",
    "    # act_R_7 = Activation('relu')(bn1_R_7)\n",
    "    # max1_R_7 = MaxPooling1D(2,2)(act_R_7)\n",
    "\n",
    "    # conv1_R_8 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_7)\n",
    "    # conv2_R_8 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_8)\n",
    "    # bn1_R_8 = BatchNormalization()(conv2_R_8)\n",
    "    # act_R_8 = Activation('relu')(bn1_R_8)\n",
    "    # max1_R_8 = MaxPooling1D(2,2)(act_R_8)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_2)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffd87d-c430-456f-82cc-e2e27a14a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"D:/Journal/WESAD_Model/Rhythm_layer_setting/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2dc8e-edde-4ee4-bc59-ff5b3c0a22ba",
   "metadata": {},
   "source": [
    "## layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef3cf0-f9f4-492d-b832-a6efb0939a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer1_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca730e-3993-445a-a8cd-6bc2b8604080",
   "metadata": {},
   "source": [
    "#  layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849bfe0-766d-4cb6-afbd-82eb4df648be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer2_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905741b6-24ad-4ae6-a884-e9c0745a3fae",
   "metadata": {},
   "source": [
    "# layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120df815-463e-4d3f-92b4-f8dc536d9bb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer3_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f43e02-85d4-4355-a166-213cf973d8bc",
   "metadata": {},
   "source": [
    "# layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fd56c-8c2e-45cb-9785-5629d5585226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_3)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf4649-f941-4625-a6b3-d0ab5c443c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer4_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ded1a-37ea-4852-8805-11c735261dcf",
   "metadata": {},
   "source": [
    "# layer 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c401337-ed09-4c87-b25a-a4189b14b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a8a2e-f119-495b-bbe2-d5f7ccdd47e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer5_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313ae37-601a-4fce-987f-31a36d8e6f28",
   "metadata": {},
   "source": [
    "# layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6220ef-cbfd-429a-8183-b56e1797a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_5)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e7166-5a29-4792-bcd8-4167ddf18b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer6_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6fec0-0224-46fd-a853-56929260a7f3",
   "metadata": {},
   "source": [
    "# layer 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a28ae0-e4dd-4899-b0b3-93cc41c2bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    conv1_R_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_5)\n",
    "    conv2_R_6 = Conv1D(512, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_6)\n",
    "    bn1_R_6 = BatchNormalization()(conv2_R_6)\n",
    "    act_R_6 = Activation('relu')(bn1_R_6)\n",
    "    max1_R_6 = MaxPooling1D(2,2)(act_R_6)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_6)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65418a6-80f7-4168-9199-b92f88684cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for window in window_list:\n",
    "\n",
    "    print(\"======================================\" + str(window) + \"======================================\")\n",
    "    \n",
    "    train_rhythm, train_y = load_data(person, 'rhythm', window)\n",
    "\n",
    "    train_r, test_r, train_label, test_label = train_test_split(train_rhythm, train_y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                stratify=train_y,\n",
    "                                                                random_state=128,\n",
    "                                                                shuffle=True)\n",
    "    \n",
    "    train_r, val_r, train_label, val_label = train_test_split(train_r, train_label,\n",
    "                                                             test_size=0.25,\n",
    "                                                             stratify=train_label,\n",
    "                                                             random_state=128,\n",
    "                                                             shuffle=True)\n",
    "    print(train_r.shape, val_r.shape, test_r.shape)\n",
    "    \n",
    "    class_weight = cal_class_weight(train_label)\n",
    "    train_label = to_categorical(train_label)\n",
    "    val_label = to_categorical(val_label)\n",
    "    test_label = to_categorical(test_label)\n",
    "\n",
    "    model_r = rhythm_model(train_r.shape[1])\n",
    "    model_r.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model_r.fit(train_r, train_label,\n",
    "                          validation_data=(val_r, val_label),\n",
    "                          epochs=200,\n",
    "                          batch_size=32,\n",
    "                          callbacks=[early_stopping],\n",
    "                          class_weight = class_weight\n",
    "                         )\n",
    "\n",
    "    scores = model_r.evaluate(test_r, test_label)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = model_r.predict(test_r)\n",
    "    Plot_confusion_matrix(test_label, pred)\n",
    "    \n",
    "    model_r.save(save_model_path + 'wesad_rhythm_' + str(window) + 'layer7_'+ '6,2,2' + '(' + str(np.round(scores[1]*100,2)) + ')_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf332f7f-3c0d-4d75-ba8a-ba23eeb9b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc897320-c283-4930-b3a1-6cae4908bb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b68e999-fa50-4c3e-b4be-da39b2cfa6d2",
   "metadata": {},
   "source": [
    "# Rhythm 5-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa800f-295d-4450-a6c7-1fd8c12245ee",
   "metadata": {},
   "source": [
    "# 5 layer and 3 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6eea9d-b9c6-48f4-83ac-f46c3bdbd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', sampling_rate*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b63b8-6cd7-41e3-93a5-2a4294dc66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_4)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dea556-d3ca-4167-b399-335efffc3b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## layer 실험\n",
    "number = 1\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Beat_Rhythm_5Fold_실험/\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "\n",
    "for train_index, test_index in skf.split(train_rhythm, train_y):\n",
    "    X_train_b, X_test_b = train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)\n",
    "    class_weight = cal_class_weight(Y_train)\n",
    "\n",
    "    MAUS_beat_model = rhythm_model(X_train_b.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    MAUS_beat_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = MAUS_beat_model.fit(X_train_b, y_train, \n",
    "                        validation_data=(X_test_b, y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        callbacks=[callback_lr],\n",
    "                        class_weight=class_weight\n",
    "                       ) \n",
    "    \n",
    "    \n",
    "    scores = MAUS_beat_model.evaluate(X_test_b, y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = MAUS_beat_model.predict(X_test_b)\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "    \n",
    "    \n",
    "    MAUS_beat_model.save(save_model_path + 'WESAD_rhythm_8020_5_layer_(0.0001)_Fold_'  +str(number)+ '(' + str(np.round(scores[1]*100,2)) + ').h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13237ca0-c9cb-4fde-8127-3c58882f40f8",
   "metadata": {},
   "source": [
    "# 6 layer and 8 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96ee38-7ff4-4a81-abec-7cefefd8e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_beat, train_rhythm, train_y = load_data(person, 'beat', 'rhythm', sampling_rate*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e5c6a-bedf-4ee5-ba0f-03b6a8ac56c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_model(re_X_train_r):\n",
    "    input_rhythm = Input(shape=(re_X_train_r,1), name = 'input_rhythm')\n",
    "\n",
    "    conv1_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(input_rhythm)\n",
    "    conv2_R = Conv1D(8, 5, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R)\n",
    "    bn1_R = BatchNormalization()(conv2_R)\n",
    "    act_R = Activation('relu')(bn1_R)\n",
    "    max1_R = MaxPooling1D(2,2)(act_R)\n",
    "\n",
    "    conv1_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R)\n",
    "    conv2_R_1 = Conv1D(16, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_1)\n",
    "    bn1_R_1 = BatchNormalization()(conv2_R_1)\n",
    "    act_R_1 = Activation('relu')(bn1_R_1)\n",
    "    max1_R_1 = MaxPooling1D(2,2)(act_R_1)\n",
    "\n",
    "\n",
    "    conv1_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_1)\n",
    "    conv2_R_2 = Conv1D(32, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_2)\n",
    "    bn1_R_2 = BatchNormalization()(conv2_R_2)\n",
    "    act_R_2 = Activation('relu')(bn1_R_2)\n",
    "    max1_R_2 = MaxPooling1D(2,2)(act_R_2)\n",
    "\n",
    "\n",
    "    conv1_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_2)\n",
    "    conv2_R_3 = Conv1D(64, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_3)\n",
    "    bn1_R_3 = BatchNormalization()(conv2_R_3)\n",
    "    act_R_3 = Activation('relu')(bn1_R_3)\n",
    "    max1_R_3 = MaxPooling1D(2,2)(act_R_3)\n",
    "\n",
    "\n",
    "    conv1_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_3)\n",
    "    conv2_R_4 = Conv1D(128, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_4)\n",
    "    bn1_R_4 = BatchNormalization()(conv2_R_4)\n",
    "    act_R_4 = Activation('relu')(bn1_R_4)\n",
    "    max1_R_4 = MaxPooling1D(2,2)(act_R_4)\n",
    "\n",
    "    conv1_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(max1_R_4)\n",
    "    conv2_R_5 = Conv1D(256, 3, activation=None, padding='same', kernel_initializer=weight_init)(conv1_R_5)\n",
    "    bn1_R_5 = BatchNormalization()(conv2_R_5)\n",
    "    act_R_5 = Activation('relu')(bn1_R_5)\n",
    "    max1_R_5 = MaxPooling1D(2,2)(act_R_5)\n",
    "\n",
    "    GAP_R = GlobalAveragePooling1D()(max1_R_5)\n",
    "\n",
    "    re_R = Reshape((1, GAP_R.shape[1]))(GAP_R)\n",
    "    x_R_LSTM = LSTM(128,return_sequences=True)(re_R)\n",
    "    x_R_LSTM2 = LSTM(64, return_sequences=True)(x_R_LSTM)\n",
    "    fl_f = Flatten()(x_R_LSTM2)\n",
    "\n",
    "    den1 = Dense(128, activation='relu')(fl_f)\n",
    "    den2 = Dense(64, activation='relu')(den1)\n",
    "\n",
    "    fusion_output = Dense(4, activation='softmax')(den2)\n",
    "\n",
    "    fusion_model = Model(inputs= input_rhythm, outputs= fusion_output)\n",
    "    fusion_model.summary()\n",
    "    \n",
    "    return fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654fdd3-bff9-4b93-bdff-cdad868892dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## layer 실험\n",
    "number = 1\n",
    "save_model_path = \"D:/Journal/WESAD_Model/Beat_Rhythm_5Fold_실험/\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=128)\n",
    "\n",
    "for train_index, test_index in skf.split(train_rhythm, train_y):\n",
    "    X_train_b, X_test_b = train_rhythm[train_index], train_rhythm[test_index]\n",
    "    Y_train, Y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "    y_train = to_categorical(Y_train)\n",
    "    y_test = to_categorical(Y_test)\n",
    "    class_weight = cal_class_weight(Y_train)\n",
    "\n",
    "    MAUS_beat_model = rhythm_model(X_train_b.shape[1])\n",
    "    callback_lr = tf.keras.callbacks.LearningRateScheduler(scheuler)\n",
    "    MAUS_beat_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = MAUS_beat_model.fit(X_train_b, y_train, \n",
    "                        validation_data=(X_test_b, y_test), \n",
    "                        epochs=50, \n",
    "                        batch_size=32,\n",
    "                        callbacks=[callback_lr],\n",
    "                        class_weight=class_weight\n",
    "                       ) \n",
    "    \n",
    "    \n",
    "    scores = MAUS_beat_model.evaluate(X_test_b, y_test)\n",
    "    Plot_lr_curve(history)\n",
    "    pred = MAUS_beat_model.predict(X_test_b)\n",
    "    Plot_confusion_matrix(y_test, pred, class_name)\n",
    "    \n",
    "    \n",
    "    MAUS_beat_model.save(save_model_path + 'WESAD_beat_8020_6_layer_(0.0001)_Fold_'  +str(number)+ '(' + str(np.round(scores[1]*100,2)) + ').h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca850c1-9f8d-4c77-b929-061520d5844b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfd978-c207-40b9-a9e1-d15c6b7d09f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_research",
   "language": "python",
   "name": "ecg1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
